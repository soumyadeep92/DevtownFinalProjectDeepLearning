# -*- coding: utf-8 -*-
"""MallCustomerClustering_KMeans.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lOuYJSAgjrmoaotRS6wln9tNUPMxlYRr

## Mall Customer Segmentation using KMeans

## 1. Importing the libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from matplotlib import pyplot as plt
# %matplotlib inline
import random
import seaborn as sns
plt.rc("font", size=14)
sns.set(style="white")
sns.set(style ="whitegrid", color_codes=True)
import warnings
warnings.filterwarnings("ignore")

"""## 2. Reading and Importing the datasets"""

with open('segment_mall_data.txt','r') as f:
    rows=f.read().split('\n')

"""## 3. Preparatory Data Analysis"""

len(rows)

rows[0]

len(rows)

"""## 4. Adding score and index columns with random data"""

# arr_items=range(1,50)
arr_items=[random.randint(0,100) for i in range(0,2000)]
print(arr_items)
print(len(arr_items))
print(len(set(arr_items)))
new_items=set(arr_items)
new_list=list(new_items)
random.shuffle(new_list)
print(len(new_list))
print(new_list)

arr_income=[]
arr_id=[]
for row in rows[1:2001]:
  arr_income.append(row.split(',')[5])
  arr_id.append(row.split(',')[5])
print(len(arr_income))
print(len(arr_id))

arr_sex=[]
for row in rows[1:2001]:
  arr_sex.append(row.split(',')[1])
print(len(arr_sex))

"""## 5. Score calculation and unique data exploration"""

def calculate_score(arr_item):
  arr_score=[]
  score=0
  for i in arr_item:
    if(i<10):
      score=random.randint(0,5)
    elif(i>10 and i<30):
      score=random.randint(5,10)
    elif(i>30 and i<50):
      score=random.randint(10,15)
    elif(i>50 and i<65):
      score=random.randint(15,30)
    elif(i>65 and i<70):
      score=random.randint(30,50)
    elif(i>70 and i<80):
      score=random.randint(50,70)
    elif(i>80 and i<90):
      score=random.randint(70,85)
    else:
      score=random.randint(85,100)
    arr_score.append(score)
  return arr_score

print(arr_items)
print(len(new_list))
arr_score=calculate_score(new_list)
arr_nonunique_score=calculate_score(arr_items)
print(len(arr_score))
print(len(arr_nonunique_score))

df=pd.DataFrame()
df['Income']=arr_income
df['Purchase_Score']=arr_nonunique_score
df['Sex']=arr_sex

print(df['Income'].shape)
print(df['Purchase_Score'].shape)

unique_purchase_score=arr_score
print(len(unique_purchase_score))
print(df['Purchase_Score'].unique().shape)

nunique_purchase_score=arr_nonunique_score
fin_index=[]
for j in unique_purchase_score:
  if(unique_purchase_score[j] in nunique_purchase_score):
     fin_index.append(nunique_purchase_score.index(unique_purchase_score[j]))
print(len(fin_index))

unique_income=[]
unique_id=[]
for i in range(len(fin_index)):
  unique_income.append(arr_income[fin_index[i]])
  unique_id.append(arr_id[fin_index[i]])
print(len(unique_income))
print(len(unique_id))

fin_df=pd.DataFrame()
fin_df['ID']=unique_id
fin_df['Income']=unique_income
fin_df['Purchase_Score']=unique_purchase_score
fin_df.shape

"""## 6. Data visualization and plotting"""

plt.figure(figsize=(50, 15))
plt.bar(arr_income[0:101],unique_income)
plt.title('Plot of Actual Income vs Unique Income')
plt.xlabel('Actual Income')
plt.ylabel('Unique Income')
plt.savefig('Plot A')
plt.show()

plt.figure(figsize=(8,8))
df['Sex'].value_counts().plot(kind='pie',autopct='%.2f%%',shadow=True,startangle=115)
plt.title('Pie chart of Sex distribution  in the dataset')
plt.savefig('Plot B')
plt.show()

sns.set(rc={'figure.figsize':(11, 8)})
sns.displot(fin_df['Purchase_Score'],bins=50)
plt.savefig('Plot C')
plt.show()

sns.set(rc={'figure.figsize':(41, 28)})
sns.countplot(x='Purchase_Score', data=df,palette='flag')
plt.savefig('Plot D')
plt.show()

plt.figure(figsize=(25,8))
plt.scatter(fin_df[0:50]['Income'],fin_df[0:50]['Purchase_Score'],marker='*',color='brown')
plt.title('Scatter Plot for Income vs Purchase_Score')
plt.xlabel('Income')
plt.ylabel('Purchase_Score')
plt.savefig('Plot E')
plt.show()

print(fin_df['Income'].shape)

"""## 7. Clustering with KMeans Algorithm"""

km=KMeans(n_clusters=3)
km

y_pred=km.fit_predict(fin_df[['Income','Purchase_Score']])
y_pred

fin_df['Clusters']=y_pred
fin_df

df0=fin_df[fin_df.Clusters==0]
df1=fin_df[fin_df.Clusters==1]
df2=fin_df[fin_df.Clusters==2]
# df3=fin_df[fin_df.Clusters==3]

plt.figure(figsize=(35,35))
plt.scatter(df0['Income'],df0['Purchase_Score'],color='red')
plt.scatter(df1['Income'],df1['Purchase_Score'],color='green')
plt.scatter(df2['Income'],df2['Purchase_Score'],color='blue')
plt.title('Scatter Plot for Income vs Purchase_Score')
plt.xlabel('Income')
plt.ylabel('Purchase_Score')
plt.legend(labels=('Cluster 1','Cluster 2','Cluster 3'),loc='upper left')
plt.savefig('Plot F')
plt.show()

scaler=MinMaxScaler()
scaler.fit(fin_df[['Purchase_Score']])
fin_df['Purchase_Score']=scaler.transform(fin_df[['Purchase_Score']])
scaler.fit(fin_df[['Income']])
fin_df['Income']=scaler.transform(fin_df[['Income']])

km=KMeans(n_clusters=3)
y_pred=km.fit_predict(fin_df[['Income','Purchase_Score']])
y_pred

fin_df['Clusters']=y_pred
fin_df

"""## 8. Predicting final clusters"""

fin_df['Clusters'].unique()

km.cluster_centers_

freezed_centroids=km.cluster_centers_

df0=fin_df[fin_df.Clusters==0]
df1=fin_df[fin_df.Clusters==1]
df2=fin_df[fin_df.Clusters==2]
# df2=fin_df[fin_df.Clusters==3]

plt.figure(figsize=(8,8))
plt.scatter(df0['Income'],df0['Purchase_Score'],color='red')
plt.scatter(df1['Income'],df1['Purchase_Score'],color='green')
plt.scatter(df2['Income'],df2['Purchase_Score'],color='blue')
plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],marker='*',color='black',label='centroid')
plt.title('Scatter Plot for Income vs Purchase_Score')
plt.xlabel('Income')
plt.ylabel('Purchase_Score')
plt.legend(labels=('Cluster 1','Cluster 2','Cluster 3'),loc='upper left')
plt.savefig('Plot G')
plt.show()

"""## 9. Calculating Sum of Squared Error"""

sse=[]
for i in range(1,10):
  km1=KMeans(n_clusters=i)
  km1.fit(fin_df[['Income','Purchase_Score']])
  sse.append(km1.inertia_)
print(sse)

plt.figure(figsize=(8,8))
plt.xlabel('Range')
plt.ylabel('Sum of squared error')
plt.title('Elbow curve for the sse')
plt.plot(range(1,10),sse)
plt.savefig('Plot H')
plt.show()

"""## 10. Predicting and displaying results"""

income_sample=175998
sample_score=44
new_arr=[int(i) for i in arr_income if i!='Income']
new_arr.sort()
min_inc=new_arr[0]
max_inc=new_arr[len(new_arr)-1]
inc_minmax=(income_sample-min_inc)/(max_inc-min_inc)
print(min_inc,max_inc)
score_minmax=sample_score/100
print(km.predict([[inc_minmax,score_minmax]])[0])
print('Thus the income 175998 and the purchase score of 44 belong to cluster 1 or Group 2')

"""## 11. Writing the pickle file"""

#import pickle
#pickle.dump(freezed_centroids, open('model.pkl','wb'))